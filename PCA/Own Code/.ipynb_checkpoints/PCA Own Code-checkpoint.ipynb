{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding our very own PCA\n",
    "In this Notebook, we are going to code our own PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Getting data\n",
    "We will use random data on Normal distribution in our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2344234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec1 = np.array([0,0,0])\n",
    "cov_mat1 = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "X = np.random.multivariate_normal(mean_vec1, cov_mat1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Getting Co-Variance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.43340112,  0.21963303,  0.00955885],\n",
       "       [ 0.21963303,  0.83918163, -0.0329771 ],\n",
       "       [ 0.00955885, -0.0329771 ,  0.99409076]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.cov is a good function in Numpy that takes 1D or 2D type data and returns another matrix having\n",
    "# covariance values between each pair\n",
    "\n",
    "# However, in case of 2D data, it finds Covariance between rows. Since our features are stacked as\n",
    "# columns, we need to Transpose our data\n",
    "\n",
    "X_transpose = X.T\n",
    "cov = np.cov(X_transpose)\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Finding the Eigen Vectors and Eigen Values from the Co-Variance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.50577087, 0.76174769, 0.99915494]),\n",
       " array([[ 0.94973472,  0.30935084,  0.04802095],\n",
       "        [ 0.31304638, -0.93965855, -0.13799916],\n",
       "        [-0.00243314, -0.14609538,  0.98926752]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linear_algebra has a nice function called eig() that takes in input co-variance matrix and \n",
    "# returns Eigen Values and Eigen Vectors\n",
    "\n",
    "np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, it returns a tuple of Eigen Values and Eigen Vectors\n",
    "\n",
    "# 1-> First of all, Eigen Vectors are column-wise and not row-wise, i.e. first eigen vector is \n",
    "#    formed by first element from each row in matrix and so on.....\n",
    "# 2-> Secondly, Eigen values are not in descending order as we would like them to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val, eig_vectors = np.linalg.eig(cov)  # Got the eigen values and eigen vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Sorting the Eigen Vectors and Eigen values in descending order of Eigen Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.505770867195348, array([ 0.94973472,  0.31304638, -0.00243314])),\n",
       " (0.9991549441401951, array([ 0.04802095, -0.13799916,  0.98926752])),\n",
       " (0.7617476873346821, array([ 0.30935084, -0.93965855, -0.14609538]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a new list having list of Eigen Value, Eigen Vector pair\n",
    "# Then we will call sort on it\n",
    "\n",
    "eig_val_vector_pairs = []\n",
    "for i in range(len(eig_val)) :\n",
    "    eig_vec = eig_vectors[:, i]   # Getting the corrseponding Eigen Vector by selecting ith column\n",
    "    eig_val_vector_pairs.append((eig_val[i], eig_vec))  # Appending a tuple of Eigen Value-Vector\n",
    "\n",
    "# Let's sort the Eigen Value-Vector List in decreasing order\n",
    "eig_val_vector_pairs.sort(reverse=True)\n",
    "\n",
    "eig_val_vector_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an excercise, you can use the built-in PCA and see that the Eigen Vectors (pca.components_) and the Eigen Values (pca.explained_variance_) have the same values as our version of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference in results\n",
    "One thing that may be different in our results and the built-in PCA results can be that the Eigen-Vectors that the built-in PCA chose are completely negative to the direction that we have chosen.\n",
    "\n",
    "However, I think you are smart enough to understand that it doesn't matter anyway"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
